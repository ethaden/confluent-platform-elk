---
services:
  zookeeper1:
    image: confluentinc/cp-zookeeper:${CP_VERSION}
    hostname: zookeeper1
    #container_name: zookeeper1
    restart: always
    ports:
      - "21811:21811"
      - "31801:31801"
      - "21801:21801"
    volumes:
      - data-zookeeper-log-1:/var/lib/zookeeper/log
      - data-zookeeper-data-1:/var/lib/zookeeper/data
    environment:
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_JMX_HOSTNAME: zookeeper1
      ZOOKEEPER_CLIENT_PORT: 21811
      ZOOKEEPER_JMX_PORT: 21801
      ZOOKEEPER_SERVERS: zookeeper1:2888:3888;zookeeper2:2888:3888;zookeeper3:2888:3888
 
  zookeeper2:
    image: confluentinc/cp-zookeeper:${CP_VERSION}
    hostname: zookeeper2
    #container_name: zookeeper2
    restart: always
    ports:
      - "21812:21812"
      - "31802:31802"
      - "21802:21802"
    volumes:
      - data-zookeeper-log-2:/var/lib/zookeeper/log
      - data-zookeeper-data-2:/var/lib/zookeeper/data
    environment:
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_JMX_HOSTNAME: zookeeper2
      ZOOKEEPER_CLIENT_PORT: 21812
      ZOOKEEPER_JMX_PORT: 21802
      ZOOKEEPER_SERVERS: zookeeper1:2888:3888;zookeeper2:2888:3888;zookeeper3:2888:3888

  zookeeper3:
    image: confluentinc/cp-zookeeper:${CP_VERSION}
    hostname: zookeeper3
    #container_name: zookeeper3
    restart: always
    ports:
      - "21813:21813"
      - "31803:31803"
      - "21803:21803"
    volumes:
      - data-zookeeper-log-3:/var/lib/zookeeper/log
      - data-zookeeper-data-3:/var/lib/zookeeper/data
    environment:
      ZOOKEEPER_TICK_TIME: 2000
      KAFKA_OPTS: "-Dzookeeper.4lw.commands.whitelist=*"
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_JMX_HOSTNAME: zookeeper3
      ZOOKEEPER_CLIENT_PORT: 21813
      ZOOKEEPER_JMX_PORT: 21803
      ZOOKEEPER_SERVERS: zookeeper1:2888:3888;zookeeper2:2888:3888;zookeeper3:2888:3888
 
  broker1:
    image: confluentinc/cp-server:${CP_VERSION}
    hostname: broker1
    #container_name: broker1
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3
    ports:
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper1:21811,zookeeper2:21812,zookeeper3:21813'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker1:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_KAFKA_REST_ENABLE: "true"

  broker2:
    image: confluentinc/cp-server:${CP_VERSION}
    hostname: broker2
    #container_name: broker2
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3
    ports:
      - "29093:29093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper1:21811,zookeeper2:21812,zookeeper3:21813'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker2:9092,PLAINTEXT_HOST://localhost:29093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_KAFKA_REST_ENABLE: "true"

  broker3:
    image: confluentinc/cp-server:${CP_VERSION}
    hostname: broker3
    #container_name: broker3
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3
    ports:
      - "29094:29094"
      - "8090:8090"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper1:21811,zookeeper2:21812,zookeeper3:21813'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker3:9092,PLAINTEXT_HOST://localhost:29094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_KAFKA_REST_ENABLE: "true"
      # /: 'http://0.0.0.0:8090'
      KAFKA_KAFKA_REST_ADVERTISED_LISTENERS: 'http://0.0.0.0:8090'
  
  schema-registry:
    image: confluentinc/cp-schema-registry:${CP_VERSION}
    hostname: schema-registry
    #container_name: schema-registry
    depends_on:
      - zookeeper1
      - zookeeper2
      - zookeeper3
      - broker1
      - broker2
      - broker3
    ports:
      - '8081:8081'
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker1:9092'
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper1:21811,zookeeper2:21812,zookeeper3:21813'
  
  # control-center:
  #   image: confluentinc/cp-enterprise-control-center:${CP_VERSION}
  #   hostname: control-center
  #   container_name: control-center
  #   depends_on:
  #     - broker1
  #     - schema-registry
  #   ports:
  #     - "9021:9021"
  #   environment:
  #     CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker1:9092'
  #     CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
  #     CONTROL_CENTER_REPLICATION_FACTOR: 1
  #     CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
  #     CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
  #     CONFLUENT_METRICS_TOPIC_REPLICATION: 1
  #     PORT: 9021

  setup:
   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
   volumes:
     - certs:/usr/share/elasticsearch/config/certs
   user: "0"
   command: >
     bash -c '
       if [ x${ELASTIC_PASSWORD} == x ]; then
         echo "Set the ELASTIC_PASSWORD environment variable in the .env file";
         exit 1;
       elif [ x${KIBANA_PASSWORD} == x ]; then
         echo "Set the KIBANA_PASSWORD environment variable in the .env file";
         exit 1;
       fi;
       if [ ! -f config/certs/ca.zip ]; then
         echo "Creating CA";
         bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
         unzip config/certs/ca.zip -d config/certs;
       fi;
       if [ ! -f config/certs/certs.zip ]; then
         echo "Creating certs";
         echo -ne \
         "instances:\n"\
         "  - name: es01\n"\
         "    dns:\n"\
         "      - es01\n"\
         "      - localhost\n"\
         "    ip:\n"\
         "      - 127.0.0.1\n"\
         "  - name: kibana\n"\
         "    dns:\n"\
         "      - kibana\n"\
         "      - localhost\n"\
         "    ip:\n"\
         "      - 127.0.0.1\n"\
         > config/certs/instances.yml;
         bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
         unzip config/certs/certs.zip -d config/certs;
       fi;
       echo "Setting file permissions"
       chown -R root:root config/certs;
       find . -type d -exec chmod 750 \{\} \;;
       find . -type f -exec chmod 640 \{\} \;;
       echo "Waiting for Elasticsearch availability";
       until curl -s --cacert config/certs/ca/ca.crt https://es01:9200 | grep -q "missing authentication credentials"; do sleep 30; done;
       echo "Setting kibana_system password";
       until curl -s -X POST --cacert config/certs/ca/ca.crt -u "elastic:${ELASTIC_PASSWORD}" -H "Content-Type: application/json" https://es01:9200/_security/user/kibana_system/_password -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do sleep 10; done;
       echo "All done!";
     '
   healthcheck:
     test: ["CMD-SHELL", "[ -f config/certs/es01/es01.crt ]"]
     interval: 1s
     timeout: 5s
     retries: 120

  es01:
   depends_on:
     setup:
       condition: service_healthy
   image: docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION}
   hostname: es01
   #container_name: es01
   labels:
     co.elastic.logs/module: elasticsearch
   volumes:
     - certs:/usr/share/elasticsearch/config/certs
     - esdata01:/usr/share/elasticsearch/data
   ports:
     - ${ES_PORT}:9200
   environment:
     - node.name=es01
     - cluster.name=${CLUSTER_NAME}
     - discovery.type=single-node
     - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
     - bootstrap.memory_lock=true
     - xpack.security.enabled=true
     - xpack.security.http.ssl.enabled=true
     - xpack.security.http.ssl.key=certs/es01/es01.key
     - xpack.security.http.ssl.certificate=certs/es01/es01.crt
     - xpack.security.http.ssl.certificate_authorities=certs/ca/ca.crt
     - xpack.security.transport.ssl.enabled=true
     - xpack.security.transport.ssl.key=certs/es01/es01.key
     - xpack.security.transport.ssl.certificate=certs/es01/es01.crt
     - xpack.security.transport.ssl.certificate_authorities=certs/ca/ca.crt
     - xpack.security.transport.ssl.verification_mode=certificate
     - xpack.license.self_generated.type=${LICENSE}
   mem_limit: ${ES_MEM_LIMIT}
   ulimits:
     memlock:
       soft: -1
       hard: -1
   healthcheck:
     test:
       [
         "CMD-SHELL",
         "curl -s --cacert config/certs/ca/ca.crt https://localhost:9200 | grep -q 'missing authentication credentials'",
       ]
     interval: 10s
     timeout: 10s
     retries: 120

  kibana:
   depends_on:
     es01:
       condition: service_healthy
   image: docker.elastic.co/kibana/kibana:${STACK_VERSION}
   hostname: kibana
   #container_name: kibana
   labels:
     co.elastic.logs/module: kibana
   volumes:
     - certs:/usr/share/kibana/config/certs
     - kibanadata:/usr/share/kibana/data
   ports:
     - ${KIBANA_PORT}:5601
   environment:
     - SERVERNAME=kibana
     - ELASTICSEARCH_HOSTS=https://es01:9200
     - ELASTICSEARCH_USERNAME=kibana_system
     - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
     - ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES=config/certs/ca/ca.crt
     - XPACK_SECURITY_ENCRYPTIONKEY=${ENCRYPTION_KEY}
     - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${ENCRYPTION_KEY}
     - XPACK_REPORTING_ENCRYPTIONKEY=${ENCRYPTION_KEY}
   mem_limit: ${KB_MEM_LIMIT}
   healthcheck:
     test:
       [
         "CMD-SHELL",
         "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'",
       ]
     interval: 10s
     timeout: 10s
     retries: 120

  # We configure filebeat to automatically grab log output of all docker containers.
  filebeat01:
   depends_on:
     es01:
       condition: service_healthy
   image: docker.elastic.co/beats/filebeat:${STACK_VERSION}
   hostname: filebeat01
   user: root
   volumes:
     - certs:/usr/share/filebeat/certs
     - filebeatdata01:/usr/share/filebeat/data
     #- "./filebeat_ingest_data/:/usr/share/filebeat/ingest_data/"
     - "./config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro"
     - "/var/lib/docker/containers:/var/lib/docker/containers:ro"
     - "/var/run/docker.sock:/var/run/docker.sock:ro"
   environment:
     - ELASTIC_USER=elastic
     - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
     - ELASTIC_HOSTS=https://es01:9200
     - KIBANA_HOSTS=http://kibana:5601
    # - LOGSTASH_HOSTS=http://logstash01:9600
   command: --strict.perms=false -e

  # logstash01:
  #  depends_on:
  #    es01:
  #      condition: service_healthy
  #    kibana:
  #      condition: service_healthy
  #  image: docker.elastic.co/logstash/logstash:${STACK_VERSION}
  #  hostname: logstash01
  #  labels:
  #    co.elastic.logs/module: logstash
  #  user: root
  #  volumes:
  #    - certs:/usr/share/logstash/certs
  #    - logstashdata01:/usr/share/logstash/data
  #    - "./logstash_ingest_data/:/usr/share/logstash/ingest_data/"
  #    - "./config/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro"
  #  environment:
  #    - xpack.monitoring.enabled=false
  #    - ELASTIC_USER=elastic
  #    - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
  #    - ELASTIC_HOSTS=https://es01:9200

volumes:
  data-zookeeper-log-1:
    driver: local
  data-zookeeper-data-1:
    driver: local
  data-zookeeper-log-2:
    driver: local
  data-zookeeper-data-2:
    driver: local
  data-zookeeper-log-3:
    driver: local
  data-zookeeper-data-3:
    driver: local
  certs:
    driver: local
  esdata01:
    driver: local
  kibanadata:
    driver: local
  metricbeatdata01:
    driver: local
  filebeatdata01:
    driver: local
  logstashdata01:
    driver: local
